{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b20b4a",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "In this phase it would be developed the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a02a66",
   "metadata": {},
   "source": [
    "# Modelling Notebook\n",
    "According to the exploration of the boxplots the roots may have higher values in all of the metrics.\n",
    "The baseline solution proposed would be generating a simple program that selects the node with higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d03131",
   "metadata": {},
   "source": [
    "## Configurations of the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ac6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "target = 'is_root'\n",
    "folds_path = './data/cross_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "444c855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function declaration\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_metrics(df, y_pred, target='is_root'):\n",
    "    \"\"\"\n",
    "    For each (sentence, language), select the vertex with the highest predicted score.\n",
    "    Compare it with the actual root vertex (where is_root == 1) and return:\n",
    "        - overall accuracy\n",
    "        - per-language accuracy breakdown\n",
    "        - total and correct predictions\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): overall accuracy\n",
    "        lang_stats (dict): per-language {'correct': int, 'total': int, 'accuracy': float}\n",
    "        total (int): total number of predictions\n",
    "        correct (int): number of correct predictions\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['y_pred'] = y_pred\n",
    "\n",
    "    # Group by sentence and language\n",
    "    groups = df.groupby(['sentence', 'language'])\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    lang_stats = {}\n",
    "\n",
    "    for (sentence, language), group in groups:\n",
    "        # Skip if no actual root\n",
    "        true_root_row = group[group[target] == 1]\n",
    "        if true_root_row.empty:\n",
    "            continue\n",
    "\n",
    "        true_vertex = true_root_row['vertex'].values[0]\n",
    "        predicted_vertex = group.loc[group['y_pred'].idxmax(), 'vertex']\n",
    "\n",
    "        is_correct = predicted_vertex == true_vertex\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "\n",
    "        # Track per-language\n",
    "        if language not in lang_stats:\n",
    "            lang_stats[language] = {'correct': 0, 'total': 0}\n",
    "        lang_stats[language]['correct'] += int(is_correct)\n",
    "        lang_stats[language]['total'] += 1\n",
    "\n",
    "    # Compute per-language accuracy\n",
    "    for lang in lang_stats:\n",
    "        lang_total = lang_stats[lang]['total']\n",
    "        lang_correct = lang_stats[lang]['correct']\n",
    "        lang_stats[lang]['accuracy'] = lang_correct / lang_total if lang_total > 0 else 0\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, lang_stats, total, correct\n",
    "\n",
    "def extract_features(df, features):\n",
    "    # Create 'avg_metrics' if needed\n",
    "    if 'avg_metrics' in features and 'avg_metrics' not in df.columns:\n",
    "        df['avg_metrics'] = df[['degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']].mean(axis=1)\n",
    "    \n",
    "    return df[features].values\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def test_model(model, folds_path, features, target, num_folds=5):\n",
    "    metrics = {\n",
    "        'train': pd.DataFrame(columns=['Accuracy']),\n",
    "        'test': pd.DataFrame(columns=['Accuracy'])\n",
    "    }\n",
    "    \n",
    "    language_stats = {\n",
    "        'train': {},\n",
    "        'test': {}\n",
    "    }\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        train_path = os.path.join(folds_path, f'fold_{fold}_train.csv')\n",
    "        test_path = os.path.join(folds_path, f'fold_{fold}_test.csv')\n",
    "\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        # Train model\n",
    "        X_train = extract_features(train_df, features)\n",
    "        y_train = train_df[target].values\n",
    "        X_test = extract_features(test_df, features)\n",
    "        y_test = test_df[target].values\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Evaluate top-vertex prediction\n",
    "        train_acc, train_lang_stats, train_total, train_correct = get_metrics(train_df, y_proba_train, target)\n",
    "        test_acc, test_lang_stats, test_total, test_correct = get_metrics(test_df, y_proba_test, target)\n",
    "\n",
    "        print(f\"Fold-{fold}\")\n",
    "        print(f\"  Train Accuracy: {train_acc:.4f} ({train_correct}/{train_total})\")\n",
    "        print(f\"  Test Accuracy:  {test_acc:.4f} ({test_correct}/{test_total})\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics['train'].loc[f'Fold {fold}'] = [train_acc]\n",
    "        metrics['test'].loc[f'Fold {fold}'] = [test_acc]\n",
    "        language_stats['train'][f'Fold {fold}'] = train_lang_stats\n",
    "        language_stats['test'][f'Fold {fold}'] = test_lang_stats\n",
    "\n",
    "    return metrics, language_stats\n",
    "\n",
    "\n",
    "def print_metrics(metrics):    \n",
    "    print(\"\\n=== Average Metrics Across Folds ===\")\n",
    "    print(\"\\nTrain:\")\n",
    "    print(metrics['train'].mean())\n",
    "    print(\"\\nTest:\")\n",
    "    print(metrics['test'].mean())\n",
    "\n",
    "\n",
    "def summarize_model_results(model_name, metrics, language_stats):\n",
    "    \"\"\"\n",
    "    Generate a summary row for the given model.\n",
    "    \n",
    "    Returns a DataFrame with:\n",
    "    - model_name\n",
    "    - train_mean_accuracy\n",
    "    - test_mean_accuracy\n",
    "    - average test accuracy per language\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'model': model_name,\n",
    "        'Train Accuracy': metrics['train']['Accuracy'].mean(),\n",
    "        'Test Accuracy': metrics['test']['Accuracy'].mean()\n",
    "    }\n",
    "\n",
    "    # Aggregate language scores across folds\n",
    "    lang_totals = {}\n",
    "    for fold_stats in language_stats['test'].values():\n",
    "        for lang, stats in fold_stats.items():\n",
    "            if lang not in lang_totals:\n",
    "                lang_totals[lang] = {'correct': 0, 'total': 0}\n",
    "            lang_totals[lang]['correct'] += stats['correct']\n",
    "            lang_totals[lang]['total'] += stats['total']\n",
    "\n",
    "    # Compute mean accuracy per language\n",
    "    for lang, stats in lang_totals.items():\n",
    "        if stats['total'] > 0:\n",
    "            summary[lang] = stats['correct'] / stats['total']\n",
    "        else:\n",
    "            summary[lang] = None  # or 0.0\n",
    "\n",
    "    return pd.DataFrame([summary])\n",
    "\n",
    "def save_model(summary_df):\n",
    "    results_path = \"./data/models/all_models.csv\"\n",
    "\n",
    "    # Load existing results or create a new one with same columns\n",
    "    if os.path.exists(results_path):\n",
    "        combined_results = pd.read_csv(results_path)\n",
    "\n",
    "        # Ensure 'model' column exists in file\n",
    "        if 'model' not in combined_results.columns:\n",
    "            raise ValueError(\"Existing file is missing the 'model' column.\")\n",
    "    else:\n",
    "        # Initialize with correct columns from summary_df\n",
    "        combined_results = pd.DataFrame(columns=summary_df.columns)\n",
    "\n",
    "    # Ensure 'model' column exists in summary_df\n",
    "    if 'model' not in summary_df.columns:\n",
    "        raise ValueError(\"The summary_df must contain a 'model' column.\")\n",
    "\n",
    "    # Drop duplicate models\n",
    "    combined_results = combined_results[~combined_results['model'].isin(summary_df['model'])]\n",
    "\n",
    "    # Append new and save\n",
    "    combined_results = pd.concat([combined_results, summary_df], ignore_index=True)\n",
    "    combined_results.to_csv(results_path, index=False)\n",
    "\n",
    "    print(\"Updated combined results:\")\n",
    "    print(combined_results.head())\n",
    "    print(\"✅ Saved summary to:\", results_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfaca8",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3067f6",
   "metadata": {},
   "source": [
    "### Logistic Regression V1 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee3a541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2740 (2302/8400)\n",
      "  Test Accuracy:  0.2581 (542/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2688 (2258/8400)\n",
      "  Test Accuracy:  0.2814 (591/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2664 (2238/8400)\n",
      "  Test Accuracy:  0.2867 (602/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2707 (2274/8400)\n",
      "  Test Accuracy:  0.2743 (576/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2752 (2312/8400)\n",
      "  Test Accuracy:  0.2562 (538/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.271048\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.271333\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0  LogReg_V1        0.271048       0.271333  ...   0.274      0.3    0.344\n",
      "\n",
      "[1 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adria Espinoza\\AppData\\Local\\Temp\\ipykernel_14496\\44031580.py:180: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_results = pd.concat([combined_results, summary_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Example usage\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "metrics, language_stats = test_model(log_reg, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"LogReg_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7360c74",
   "metadata": {},
   "source": [
    "### Logistic Regression with Feature Engineering\n",
    "\n",
    "In that model we have applied the linear model, but with a new variable the average betweeen the metrics extracted from the sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c5167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2739 (2301/8400)\n",
      "  Test Accuracy:  0.2581 (542/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2680 (2251/8400)\n",
      "  Test Accuracy:  0.2810 (590/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2667 (2240/8400)\n",
      "  Test Accuracy:  0.2871 (603/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2708 (2275/8400)\n",
      "  Test Accuracy:  0.2733 (574/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2755 (2314/8400)\n",
      "  Test Accuracy:  0.2586 (543/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.270976\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.271619\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0  LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1  LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "\n",
      "[2 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm', 'avg_metrics']\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "metrics, language_stats = test_model(log_reg, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"LogReg_V2\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496cb2d",
   "metadata": {},
   "source": [
    "### Linear Model V3 - Tunning Parameters\n",
    "Applied Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb2148ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2744 (2305/8400)\n",
      "  Test Accuracy:  0.2562 (538/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2682 (2253/8400)\n",
      "  Test Accuracy:  0.2795 (587/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2660 (2234/8400)\n",
      "  Test Accuracy:  0.2867 (602/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2700 (2268/8400)\n",
      "  Test Accuracy:  0.2757 (579/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2755 (2314/8400)\n",
      "  Test Accuracy:  0.2533 (532/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.27081\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.270286\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "\n",
      "[3 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "\n",
    "# Define parameter grid for tuning alpha\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Ridge model with grid search (inner CV to pick alpha)\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',          # Change to 'l1' or 'elasticnet' if needed\n",
    "    C=0.1,                 # Stronger regularization (default is 1.0)\n",
    "    solver='liblinear',    # Use 'saga' for elasticnet\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "metrics, language_stats = test_model(log_reg, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"LogReg_Regularized\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1e4bd",
   "metadata": {},
   "source": [
    "## Non Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0238cbf",
   "metadata": {},
   "source": [
    "### Random Forest V1 - Baseline (no feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8025c1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.8581 (7208/8400)\n",
      "  Test Accuracy:  0.2495 (524/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.8586 (7212/8400)\n",
      "  Test Accuracy:  0.2686 (564/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.8601 (7225/8400)\n",
      "  Test Accuracy:  0.2576 (541/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.8602 (7226/8400)\n",
      "  Test Accuracy:  0.2714 (570/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.8596 (7221/8400)\n",
      "  Test Accuracy:  0.2557 (537/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.859333\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.260571\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "\n",
      "[4 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# V1\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "rf = RandomForestClassifier() # overfitting de manual\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f96be",
   "metadata": {},
   "source": [
    "### Random Forest V2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa616dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.8581 (7208/8400)\n",
      "  Test Accuracy:  0.2490 (523/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.8586 (7212/8400)\n",
      "  Test Accuracy:  0.2638 (554/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.8601 (7225/8400)\n",
      "  Test Accuracy:  0.2695 (566/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.8604 (7227/8400)\n",
      "  Test Accuracy:  0.2624 (551/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.8596 (7221/8400)\n",
      "  Test Accuracy:  0.2590 (544/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.859357\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.260762\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "4               RF_V2        0.859357       0.260762  ...   0.302    0.272    0.316\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# V2\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm', 'avg_metrics']\n",
    "rf = RandomForestClassifier() # overfitting de manual\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V2\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de34c4",
   "metadata": {},
   "source": [
    "### Random Forest V3 - Changing Parameters of the tree\n",
    "\n",
    "We have decided to choose the features without the \"avg_metrics\", since the results are quite better without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c3fb959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2960 (2486/8400)\n",
      "  Test Accuracy:  0.2767 (581/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2879 (2418/8400)\n",
      "  Test Accuracy:  0.2986 (627/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2882 (2421/8400)\n",
      "  Test Accuracy:  0.3033 (637/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2895 (2432/8400)\n",
      "  Test Accuracy:  0.2914 (612/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2944 (2473/8400)\n",
      "  Test Accuracy:  0.2676 (562/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.29119\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.287524\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "4               RF_V2        0.859357       0.260762  ...   0.302    0.272    0.316\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# V3\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "rf = RandomForestClassifier(max_depth=5,               # Restrict tree depth\n",
    "    min_samples_split=10,      # Fewer splits\n",
    "    min_samples_leaf=5,        # Larger leaves\n",
    "    n_estimators=100,          # Keep moderate number of trees\n",
    "    random_state=42)\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V3\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8036c5",
   "metadata": {},
   "source": [
    "### Boosting V1 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa81b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.3537 (2971/8400)\n",
      "  Test Accuracy:  0.2800 (588/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.3615 (3037/8400)\n",
      "  Test Accuracy:  0.2971 (624/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.3499 (2939/8400)\n",
      "  Test Accuracy:  0.2905 (610/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.3507 (2946/8400)\n",
      "  Test Accuracy:  0.2919 (613/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.3548 (2980/8400)\n",
      "  Test Accuracy:  0.2738 (575/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.354119\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.286667\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "4               RF_V2        0.859357       0.260762  ...   0.302    0.272    0.316\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Feature selection ===\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "\n",
    "# === XGBoost Classifier with regularization ===\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# === Evaluate model ===\n",
    "metrics, language_stats = test_model(xgb_model, folds_path, features, target)\n",
    "\n",
    "# === Print + save results ===\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"XGB_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b66b7d",
   "metadata": {},
   "source": [
    "### Boosting V2 - Adding feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ccfafaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.3527 (2963/8400)\n",
      "  Test Accuracy:  0.2729 (573/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.3421 (2874/8400)\n",
      "  Test Accuracy:  0.3033 (637/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.3517 (2954/8400)\n",
      "  Test Accuracy:  0.3067 (644/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.3533 (2968/8400)\n",
      "  Test Accuracy:  0.2867 (602/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.3512 (2950/8400)\n",
      "  Test Accuracy:  0.2710 (569/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.350214\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.288095\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "4               RF_V2        0.859357       0.260762  ...   0.302    0.272    0.316\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Feature selection ===\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm', 'avg_metrics']\n",
    "\n",
    "# === XGBoost Classifier with regularization ===\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# === Evaluate model ===\n",
    "metrics, language_stats = test_model(xgb_model, folds_path, features, target)\n",
    "\n",
    "# === Print + save results ===\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"XGB_V2\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4c41e",
   "metadata": {},
   "source": [
    "### Boosting V3 - Changing Boosting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab7eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2975 (2499/8400)\n",
      "  Test Accuracy:  0.2795 (587/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2904 (2439/8400)\n",
      "  Test Accuracy:  0.3048 (640/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2917 (2450/8400)\n",
      "  Test Accuracy:  0.3067 (644/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2907 (2442/8400)\n",
      "  Test Accuracy:  0.2914 (612/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2961 (2487/8400)\n",
      "  Test Accuracy:  0.2671 (561/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.293262\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "Accuracy    0.289905\n",
      "dtype: float64\n",
      "Updated combined results:\n",
      "                model  Train Accuracy  Test Accuracy  ...  German  Turkish  Russian\n",
      "0           LogReg_V1        0.271048       0.271333  ...   0.274    0.300    0.344\n",
      "1           LogReg_V2        0.270976       0.271619  ...   0.276    0.304    0.346\n",
      "2  LogReg_Regularized        0.270810       0.270286  ...   0.276    0.294    0.346\n",
      "3               RF_V1        0.859333       0.260571  ...   0.298    0.248    0.334\n",
      "4               RF_V2        0.859357       0.260762  ...   0.302    0.272    0.316\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "✅ Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Feature selection ===\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "\n",
    "# === XGBoost Classifier with regularization ===\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,  # L1 regularization\n",
    "    reg_lambda=1.0, # L2 regularization\n",
    "    eval_metric='logloss',\n",
    "    random_state=42)\n",
    "\n",
    "# === Evaluate model ===\n",
    "metrics, language_stats = test_model(xgb_model, folds_path, features, target)\n",
    "\n",
    "# === Print + save results ===\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"XGB_V3\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
