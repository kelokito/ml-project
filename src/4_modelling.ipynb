{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b20b4a",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "In this phase it would be developed the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a02a66",
   "metadata": {},
   "source": [
    "# Modelling Notebook\n",
    "According to the exploration of the boxplots the roots may have higher values in all of the metrics.\n",
    "The baseline solution proposed would be generating a simple program that selects the node with higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d03131",
   "metadata": {},
   "source": [
    "## Configurations of the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ac6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "target = 'is_root'\n",
    "folds_path = './data/cross_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function declaration\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_metrics(df, y_pred, target='is_root'):\n",
    "    \"\"\"\n",
    "    For each (sentence, language), select the vertex with the highest predicted score.\n",
    "    Compare it with the actual root vertex (where is_root == 1) and return:\n",
    "        - overall accuracy\n",
    "        - per-language accuracy breakdown\n",
    "        - total and correct predictions\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): overall accuracy\n",
    "        lang_stats (dict): per-language {'correct': int, 'total': int, 'accuracy': float}\n",
    "        total (int): total number of predictions\n",
    "        correct (int): number of correct predictions\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['y_pred'] = y_pred\n",
    "\n",
    "    # Group by sentence and language\n",
    "    groups = df.groupby(['sentence', 'language'])\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    lang_stats = {}\n",
    "\n",
    "    for (sentence, language), group in groups:\n",
    "        # Skip if no actual root\n",
    "        true_root_row = group[group[target] == 1]\n",
    "        if true_root_row.empty:\n",
    "            continue\n",
    "\n",
    "        true_vertex = true_root_row['vertex'].values[0]\n",
    "        predicted_vertex = group.loc[group['y_pred'].idxmax(), 'vertex']\n",
    "\n",
    "        is_correct = predicted_vertex == true_vertex\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "\n",
    "        # Track per-language\n",
    "        if language not in lang_stats:\n",
    "            lang_stats[language] = {'correct': 0, 'total': 0}\n",
    "        lang_stats[language]['correct'] += int(is_correct)\n",
    "        lang_stats[language]['total'] += 1\n",
    "\n",
    "    # Compute per-language accuracy\n",
    "    for lang in lang_stats:\n",
    "        lang_total = lang_stats[lang]['total']\n",
    "        lang_correct = lang_stats[lang]['correct']\n",
    "        lang_stats[lang]['accuracy'] = lang_correct / lang_total if lang_total > 0 else 0\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, lang_stats, total, correct\n",
    "\n",
    "def extract_features(df, features):\n",
    "    # Create 'avg_metrics' if needed\n",
    "    if 'avg_metrics' in features and 'avg_metrics' not in df.columns:\n",
    "        df['avg_metrics'] = df[['degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']].mean(axis=1)\n",
    "    \n",
    "    return df[features].values\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def test_model(model, folds_path, features, target, num_folds=5):\n",
    "    metrics = {\n",
    "        'train': pd.DataFrame(columns=['Accuracy']),\n",
    "        'test': pd.DataFrame(columns=['Accuracy'])\n",
    "    }\n",
    "    \n",
    "    language_stats = {\n",
    "        'train': {},\n",
    "        'test': {}\n",
    "    }\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        train_path = os.path.join(folds_path, f'fold_{fold}_train.csv')\n",
    "        test_path = os.path.join(folds_path, f'fold_{fold}_test.csv')\n",
    "\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        # Train model\n",
    "        X_train = extract_features(train_df, features)\n",
    "        y_train = train_df[target].values\n",
    "        X_test = extract_features(test_df, features)\n",
    "        y_test = test_df[target].values\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        # Evaluate top-vertex prediction\n",
    "        train_acc, train_lang_stats, train_total, train_correct = get_metrics(train_df, y_pred_train, target)\n",
    "        test_acc, test_lang_stats, test_total, test_correct = get_metrics(test_df, y_pred_test, target)\n",
    "\n",
    "        print(f\"Fold-{fold}\")\n",
    "        print(f\"  Train Accuracy: {train_acc:.4f} ({train_correct}/{train_total})\")\n",
    "        print(f\"  Test Accuracy:  {test_acc:.4f} ({test_correct}/{test_total})\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics['train'].loc[f'Fold {fold}'] = [train_acc]\n",
    "        metrics['test'].loc[f'Fold {fold}'] = [test_acc]\n",
    "        language_stats['train'][f'Fold {fold}'] = train_lang_stats\n",
    "        language_stats['test'][f'Fold {fold}'] = test_lang_stats\n",
    "\n",
    "    return metrics, language_stats\n",
    "\n",
    "\n",
    "def print_metrics(metrics):    \n",
    "    print(\"\\n=== Average Metrics Across Folds ===\")\n",
    "    print(\"\\nTrain:\")\n",
    "    print(metrics['train'].mean())\n",
    "    print(metrics['train'])\n",
    "\n",
    "    print(\"\\nTest:\")\n",
    "    print(metrics['test'].mean())\n",
    "    print(metrics['test'])\n",
    "\n",
    "\n",
    "def summarize_model_results(model_name, metrics, language_stats):\n",
    "    \"\"\"\n",
    "    Generate a summary row for the given model.\n",
    "    \n",
    "    Returns a DataFrame with:\n",
    "    - model_name\n",
    "    - train_mean_accuracy\n",
    "    - test_mean_accuracy\n",
    "    - average test accuracy per language\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'model': model_name,\n",
    "        'Train Accuracy': metrics['train']['Accuracy'].mean(),\n",
    "        'Test Accuracy': metrics['test']['Accuracy'].mean()\n",
    "    }\n",
    "\n",
    "    # Aggregate language scores across folds\n",
    "    lang_totals = {}\n",
    "    for fold_stats in language_stats['test'].values():\n",
    "        for lang, stats in fold_stats.items():\n",
    "            if lang not in lang_totals:\n",
    "                lang_totals[lang] = {'correct': 0, 'total': 0}\n",
    "            lang_totals[lang]['correct'] += stats['correct']\n",
    "            lang_totals[lang]['total'] += stats['total']\n",
    "\n",
    "    # Compute mean accuracy per language\n",
    "    for lang, stats in lang_totals.items():\n",
    "        if stats['total'] > 0:\n",
    "            summary[lang] = stats['correct'] / stats['total']\n",
    "        else:\n",
    "            summary[lang] = None  # or 0.0\n",
    "\n",
    "    return pd.DataFrame([summary])\n",
    "\n",
    "def save_model(summary_df):\n",
    "    results_path = \"./data/models/all_models.csv\"\n",
    "\n",
    "    # Load existing results or create a new one with same columns\n",
    "    if os.path.exists(results_path):\n",
    "        combined_results = pd.read_csv(results_path)\n",
    "\n",
    "        # Ensure 'model' column exists in file\n",
    "        if 'model' not in combined_results.columns:\n",
    "            raise ValueError(\"Existing file is missing the 'model' column.\")\n",
    "    else:\n",
    "        # Initialize with correct columns from summary_df\n",
    "        combined_results = pd.DataFrame(columns=summary_df.columns)\n",
    "\n",
    "    # Ensure 'model' column exists in summary_df\n",
    "    if 'model' not in summary_df.columns:\n",
    "        raise ValueError(\"The summary_df must contain a 'model' column.\")\n",
    "\n",
    "    # Drop duplicate models\n",
    "    combined_results = combined_results[~combined_results['model'].isin(summary_df['model'])]\n",
    "\n",
    "    # Append new and save\n",
    "    combined_results = pd.concat([combined_results, summary_df], ignore_index=True)\n",
    "    combined_results.to_csv(results_path, index=False)\n",
    "\n",
    "    print(\"Updated combined results:\")\n",
    "    print(combined_results.head())\n",
    "    print(\"âœ… Saved summary to:\", results_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfaca8",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3067f6",
   "metadata": {},
   "source": [
    "### Linear Regression V1 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee3a541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2746 (2307/8400)\n",
      "  Test Accuracy:  0.2571 (540/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2689 (2259/8400)\n",
      "  Test Accuracy:  0.2786 (585/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2668 (2241/8400)\n",
      "  Test Accuracy:  0.2886 (606/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2717 (2282/8400)\n",
      "  Test Accuracy:  0.2767 (581/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2742 (2303/8400)\n",
      "  Test Accuracy:  0.2552 (536/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.271238\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.274643\n",
      "Fold 2  0.268929\n",
      "Fold 3  0.266786\n",
      "Fold 4  0.271667\n",
      "Fold 5  0.274167\n",
      "\n",
      "Test:\n",
      "Accuracy    0.271238\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.257143\n",
      "Fold 2  0.278571\n",
      "Fold 3  0.288571\n",
      "Fold 4  0.276667\n",
      "Fold 5  0.255238\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V2        0.270762       0.270762   0.294    0.252   0.21   \n",
      "1  LinReg_V1        0.271238       0.271238   0.294    0.256   0.21   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.282   0.282  0.248  0.282  ...   0.306      0.3    0.342      0.332   \n",
      "1       0.284   0.282  0.248  0.282  ...   0.306      0.3    0.342      0.332   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0     0.22    0.288     0.252   0.280    0.298     0.35  \n",
      "1     0.22    0.286     0.252   0.278    0.304     0.35  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "metrics, language_stats = test_model(lin_reg, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"LinReg_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7360c74",
   "metadata": {},
   "source": [
    "### Linear Regression with Feature Engineering\n",
    "\n",
    "In that model we have applied the linear model, but with a new variable the average betweeen the metrics extracted from the sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94c5167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2745 (2306/8400)\n",
      "  Test Accuracy:  0.2562 (538/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2676 (2248/8400)\n",
      "  Test Accuracy:  0.2786 (585/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2657 (2232/8400)\n",
      "  Test Accuracy:  0.2871 (603/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2707 (2274/8400)\n",
      "  Test Accuracy:  0.2762 (580/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2752 (2312/8400)\n",
      "  Test Accuracy:  0.2557 (537/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.270762\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.274524\n",
      "Fold 2  0.267619\n",
      "Fold 3  0.265714\n",
      "Fold 4  0.270714\n",
      "Fold 5  0.275238\n",
      "\n",
      "Test:\n",
      "Accuracy    0.270762\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.256190\n",
      "Fold 2  0.278571\n",
      "Fold 3  0.287143\n",
      "Fold 4  0.276190\n",
      "Fold 5  0.255714\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V1        0.271238       0.271238   0.294    0.256   0.21   \n",
      "1  LinReg_V2        0.270762       0.270762   0.294    0.252   0.21   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.284   0.282  0.248  0.282  ...   0.306      0.3    0.342      0.332   \n",
      "1       0.282   0.282  0.248  0.282  ...   0.306      0.3    0.342      0.332   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0     0.22    0.286     0.252   0.278    0.304     0.35  \n",
      "1     0.22    0.288     0.252   0.280    0.298     0.35  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm', 'avg_metrics']\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "metrics, language_stats = test_model(lin_reg, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"LinReg_V2\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496cb2d",
   "metadata": {},
   "source": [
    "### Linear Model V3 - Tunning Parameters\n",
    "Applied Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb2148ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2738 (2300/8400)\n",
      "  Test Accuracy:  0.2571 (540/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2675 (2247/8400)\n",
      "  Test Accuracy:  0.2781 (584/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2661 (2235/8400)\n",
      "  Test Accuracy:  0.2876 (604/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2693 (2262/8400)\n",
      "  Test Accuracy:  0.2748 (577/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2745 (2306/8400)\n",
      "  Test Accuracy:  0.2548 (535/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.270238\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.273810\n",
      "Fold 2  0.267500\n",
      "Fold 3  0.266071\n",
      "Fold 4  0.269286\n",
      "Fold 5  0.274524\n",
      "\n",
      "Test:\n",
      "Accuracy    0.270476\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.257143\n",
      "Fold 2  0.278095\n",
      "Fold 3  0.287619\n",
      "Fold 4  0.274762\n",
      "Fold 5  0.254762\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V1        0.271238       0.271238   0.294    0.256  0.210   \n",
      "1  LinReg_V2        0.270762       0.270762   0.294    0.252  0.210   \n",
      "2      RF_V1        0.859310       0.258571   0.268    0.274  0.170   \n",
      "3      RF_V2        0.859214       0.254286   0.264    0.284  0.164   \n",
      "4      RF_V3        0.291667       0.289143   0.318    0.280  0.224   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.284   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "1       0.282   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "2       0.278   0.296  0.198  0.238  ...   0.250    0.302    0.298      0.276   \n",
      "3       0.292   0.280  0.170  0.230  ...   0.252    0.288    0.294      0.280   \n",
      "4       0.304   0.314  0.258  0.306  ...   0.308    0.314    0.332      0.354   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0    0.220    0.286     0.252   0.278    0.304    0.350  \n",
      "1    0.220    0.288     0.252   0.280    0.298    0.350  \n",
      "2    0.252    0.254     0.298   0.288    0.252    0.330  \n",
      "3    0.248    0.244     0.302   0.290    0.254    0.326  \n",
      "4    0.256    0.268     0.300   0.306    0.312    0.380  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "\n",
    "# Define parameter grid for tuning alpha\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Ridge model with grid search (inner CV to pick alpha)\n",
    "ridge_model = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid,\n",
    "    cv=3,  # inner CV within each train fold\n",
    "    scoring='neg_mean_squared_error',  # can be adjusted\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "metrics, language_stats = test_model(ridge_model, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"Ridge_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1e4bd",
   "metadata": {},
   "source": [
    "## Non Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0238cbf",
   "metadata": {},
   "source": [
    "### Random Forest V1 - Baseline (no feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8025c1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.8586 (7212/8400)\n",
      "  Test Accuracy:  0.2490 (523/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.8587 (7213/8400)\n",
      "  Test Accuracy:  0.2633 (553/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.8602 (7226/8400)\n",
      "  Test Accuracy:  0.2662 (559/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.8594 (7219/8400)\n",
      "  Test Accuracy:  0.2629 (552/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.8596 (7221/8400)\n",
      "  Test Accuracy:  0.2514 (528/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.85931\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.858571\n",
      "Fold 2  0.858690\n",
      "Fold 3  0.860238\n",
      "Fold 4  0.859405\n",
      "Fold 5  0.859643\n",
      "\n",
      "Test:\n",
      "Accuracy    0.258571\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.249048\n",
      "Fold 2  0.263333\n",
      "Fold 3  0.266190\n",
      "Fold 4  0.262857\n",
      "Fold 5  0.251429\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V1        0.271238       0.271238   0.294    0.256   0.21   \n",
      "1  LinReg_V2        0.270762       0.270762   0.294    0.252   0.21   \n",
      "2      RF_V1        0.859310       0.258571   0.268    0.274   0.17   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.284   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "1       0.282   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "2       0.278   0.296  0.198  0.238  ...   0.250    0.302    0.298      0.276   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0    0.220    0.286     0.252   0.278    0.304     0.35  \n",
      "1    0.220    0.288     0.252   0.280    0.298     0.35  \n",
      "2    0.252    0.254     0.298   0.288    0.252     0.33  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# V1\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "rf = RandomForestRegressor() # overfitting de manual\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V1\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f96be",
   "metadata": {},
   "source": [
    "### Random Forest V2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa616dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.8580 (7207/8400)\n",
      "  Test Accuracy:  0.2424 (509/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.8583 (7210/8400)\n",
      "  Test Accuracy:  0.2581 (542/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.8605 (7228/8400)\n",
      "  Test Accuracy:  0.2629 (552/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.8596 (7221/8400)\n",
      "  Test Accuracy:  0.2648 (556/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.8596 (7221/8400)\n",
      "  Test Accuracy:  0.2433 (511/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.859214\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.857976\n",
      "Fold 2  0.858333\n",
      "Fold 3  0.860476\n",
      "Fold 4  0.859643\n",
      "Fold 5  0.859643\n",
      "\n",
      "Test:\n",
      "Accuracy    0.254286\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.242381\n",
      "Fold 2  0.258095\n",
      "Fold 3  0.262857\n",
      "Fold 4  0.264762\n",
      "Fold 5  0.243333\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V1        0.271238       0.271238   0.294    0.256  0.210   \n",
      "1  LinReg_V2        0.270762       0.270762   0.294    0.252  0.210   \n",
      "2      RF_V1        0.859310       0.258571   0.268    0.274  0.170   \n",
      "3      RF_V2        0.859214       0.254286   0.264    0.284  0.164   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.284   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "1       0.282   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "2       0.278   0.296  0.198  0.238  ...   0.250    0.302    0.298      0.276   \n",
      "3       0.292   0.280  0.170  0.230  ...   0.252    0.288    0.294      0.280   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0    0.220    0.286     0.252   0.278    0.304    0.350  \n",
      "1    0.220    0.288     0.252   0.280    0.298    0.350  \n",
      "2    0.252    0.254     0.298   0.288    0.252    0.330  \n",
      "3    0.248    0.244     0.302   0.290    0.254    0.326  \n",
      "\n",
      "[4 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# V2\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm', 'avg_metrics']\n",
    "rf = RandomForestRegressor() # overfitting de manual\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V2\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de34c4",
   "metadata": {},
   "source": [
    "### Random Forest V3 - Changing Parameters of the tree\n",
    "\n",
    "We have decided to choose the features without the \"avg_metrics\", since the results are quite better without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c3fb959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1\n",
      "  Train Accuracy: 0.2958 (2485/8400)\n",
      "  Test Accuracy:  0.2762 (580/2100)\n",
      "Fold-2\n",
      "  Train Accuracy: 0.2894 (2431/8400)\n",
      "  Test Accuracy:  0.3048 (640/2100)\n",
      "Fold-3\n",
      "  Train Accuracy: 0.2863 (2405/8400)\n",
      "  Test Accuracy:  0.3062 (643/2100)\n",
      "Fold-4\n",
      "  Train Accuracy: 0.2906 (2441/8400)\n",
      "  Test Accuracy:  0.2905 (610/2100)\n",
      "Fold-5\n",
      "  Train Accuracy: 0.2962 (2488/8400)\n",
      "  Test Accuracy:  0.2681 (563/2100)\n",
      "\n",
      "=== Average Metrics Across Folds ===\n",
      "\n",
      "Train:\n",
      "Accuracy    0.291667\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.295833\n",
      "Fold 2  0.289405\n",
      "Fold 3  0.286310\n",
      "Fold 4  0.290595\n",
      "Fold 5  0.296190\n",
      "\n",
      "Test:\n",
      "Accuracy    0.289143\n",
      "dtype: float64\n",
      "        Accuracy\n",
      "Fold 1  0.276190\n",
      "Fold 2  0.304762\n",
      "Fold 3  0.306190\n",
      "Fold 4  0.290476\n",
      "Fold 5  0.268095\n",
      "Updated combined results:\n",
      "       model  Train Accuracy  Test Accuracy  Arabic  English  Hindi  \\\n",
      "0  LinReg_V1        0.271238       0.271238   0.294    0.256  0.210   \n",
      "1  LinReg_V2        0.270762       0.270762   0.294    0.252  0.210   \n",
      "2      RF_V1        0.859310       0.258571   0.268    0.274  0.170   \n",
      "3      RF_V2        0.859214       0.254286   0.264    0.284  0.164   \n",
      "4      RF_V3        0.291667       0.289143   0.318    0.280  0.224   \n",
      "\n",
      "   Indonesian  Polish   Thai  Czech  ...  Korean  Spanish  Finnish  Icelandic  \\\n",
      "0       0.284   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "1       0.282   0.282  0.248  0.282  ...   0.306    0.300    0.342      0.332   \n",
      "2       0.278   0.296  0.198  0.238  ...   0.250    0.302    0.298      0.276   \n",
      "3       0.292   0.280  0.170  0.230  ...   0.252    0.288    0.294      0.280   \n",
      "4       0.304   0.314  0.258  0.306  ...   0.308    0.314    0.332      0.354   \n",
      "\n",
      "   Italian  Chinese  Galician  German  Turkish  Russian  \n",
      "0    0.220    0.286     0.252   0.278    0.304    0.350  \n",
      "1    0.220    0.288     0.252   0.280    0.298    0.350  \n",
      "2    0.252    0.254     0.298   0.288    0.252    0.330  \n",
      "3    0.248    0.244     0.302   0.290    0.254    0.326  \n",
      "4    0.256    0.268     0.300   0.306    0.312    0.380  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "âœ… Saved summary to: ./data/models/all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# V3\n",
    "features = ['n_norm', 'degree_norm', 'closeness_norm', 'betweenness_norm', 'pagerank_norm']\n",
    "rf = RandomForestRegressor(max_depth=5,               # Restrict tree depth\n",
    "    min_samples_split=10,      # Fewer splits\n",
    "    min_samples_leaf=5,        # Larger leaves\n",
    "    n_estimators=100,          # Keep moderate number of trees\n",
    "    random_state=42)\n",
    "\n",
    "metrics, language_stats = test_model(rf, folds_path, features, target)\n",
    "\n",
    "# Average metrics summary\n",
    "print_metrics(metrics)\n",
    "\n",
    "summary_df = summarize_model_results(\"RF_V3\", metrics, language_stats)\n",
    "summary_df.head()\n",
    "save_model(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
