{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bdcc29",
   "metadata": {},
   "source": [
    "# Dataset Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69405007",
   "metadata": {},
   "source": [
    "Configure the paths and the libraries used for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adria Espinoza G\\FIB\\mds\\Q2\\ML\\ml-project\\src\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2290977",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "First we have extracted the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e526942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns\n",
      "Index(['language', 'sentence', 'n', 'edgelist', 'root'], dtype='object')\n",
      "Dataframe rows\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./data/raw_files/train.csv\")\n",
    "df['edgelist'] = df['edgelist'].apply(ast.literal_eval) # to verify that we are sending a list instead of an array\n",
    "\n",
    "print(\"Dataframe columns\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"Dataframe rows\")\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22d7a0",
   "metadata": {},
   "source": [
    "### Function declaration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91fe0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def centralities(edgelist):\n",
    "    \"\"\"\n",
    "    - edgelist is a list of node pairs e.g. [(7,2),(1,7),(1,9),...]\n",
    "    - returns a dictionary of vertex -> (centrality values)\n",
    "    \"\"\"\n",
    "    T = nx.from_edgelist(edgelist)\n",
    "    dc = nx.degree_centrality(T)\n",
    "    cc = nx.harmonic_centrality(T)\n",
    "    bc = nx.betweenness_centrality(T)\n",
    "    pc = nx.pagerank(T)\n",
    "    return {v: (dc[v], cc[v], bc[v], pc[v]) for v in T}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26d1f5",
   "metadata": {},
   "source": [
    "### Transforming the dataframe\n",
    "-  To meet the project's requirements, the following code breaks down sentences into finer granularity.\n",
    "- Instead of working with full sentences, we now operate at the level of vertices (as nodes in a sentence treemap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "205b06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         language  sentence   n  vertex    degree  closeness  betweenness  \\\n",
      "0       Japanese         2  23       6  0.090909   5.823846     0.090909   \n",
      "1       Japanese         2  23       4  0.045455   4.561122     0.000000   \n",
      "2       Japanese         2  23       2  0.136364   6.991703     0.255411   \n",
      "3       Japanese         2  23      23  0.045455   5.157179     0.000000   \n",
      "4       Japanese         2  23      20  0.090909   7.146825     0.311688   \n",
      "...          ...       ...  ..     ...       ...        ...          ...   \n",
      "197474   Russian       995  19      19  0.055556   5.005159     0.000000   \n",
      "197475   Russian       995  19       1  0.055556   6.034524     0.000000   \n",
      "197476   Russian       995  19      14  0.055556   6.034524     0.000000   \n",
      "197477   Russian       995  19       5  0.111111   6.701190     0.111111   \n",
      "197478   Russian       995  19      16  0.055556   5.005159     0.000000   \n",
      "\n",
      "        pagerank  is_root  \n",
      "0       0.048565        0  \n",
      "1       0.027162        0  \n",
      "2       0.066901        0  \n",
      "3       0.025477        0  \n",
      "4       0.042552        0  \n",
      "...          ...      ...  \n",
      "197474  0.032147        0  \n",
      "197475  0.029739        0  \n",
      "197476  0.029739        0  \n",
      "197477  0.057065        0  \n",
      "197478  0.032147        0  \n",
      "\n",
      "[197479 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "# List to collect rows for the final DataFrame\n",
    "rows = []\n",
    "\n",
    "# Iterate over DataFrame rows\n",
    "for idx, row in df.iterrows():\n",
    "    # Compute centralities\n",
    "    centrality_dict = centralities(row['edgelist'])\n",
    "    \n",
    "    # Build a flat row per node\n",
    "    for vertex, (deg, clos, betw, pr) in centrality_dict.items():\n",
    "        rows.append({\n",
    "            'language': row['language'],\n",
    "            'sentence': row['sentence'],\n",
    "            'n': row['n'],\n",
    "            'vertex': vertex,\n",
    "            'degree': deg,\n",
    "            'closeness': clos,\n",
    "            'betweenness': betw,\n",
    "            'pagerank': pr,\n",
    "            'is_root': int(vertex == row['root'])\n",
    "        })\n",
    "\n",
    "# Convert list of rows to a DataFrame\n",
    "df_filtered = pd.DataFrame(rows)\n",
    "\n",
    "print(df_filtered.head)\n",
    "df_filtered.to_csv(\"./data/preprocessed/data_preprocessed_v1.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
