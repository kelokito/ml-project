{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21b892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>vertex</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>katz</th>\n",
       "      <th>load</th>\n",
       "      <th>is_root</th>\n",
       "      <th>degree_norm</th>\n",
       "      <th>closeness_norm</th>\n",
       "      <th>betweenness_norm</th>\n",
       "      <th>pagerank_norm</th>\n",
       "      <th>katz_norm</th>\n",
       "      <th>load_norm</th>\n",
       "      <th>n_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7.547655</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933542</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.932971</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7.803968</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.068442</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.891309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.247655</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>0.218981</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.596475</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.518343</td>\n",
       "      <td>0.477072</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.803211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028838</td>\n",
       "      <td>0.196845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.171825</td>\n",
       "      <td>0.521053</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.223220</td>\n",
       "      <td>0.521053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.567474</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  sentence   n  vertex  degree  closeness  betweenness  pagerank  \\\n",
       "0   Arabic         2  21      10    0.15   7.547655     0.415789  0.070385   \n",
       "1   Arabic         2  21       8    0.15   7.803968     0.568421  0.068442   \n",
       "2   Arabic         2  21       5    0.10   6.247655     0.100000  0.051047   \n",
       "3   Arabic         2  21      13    0.05   4.803211     0.000000  0.028838   \n",
       "4   Arabic         2  21       6    0.10   7.171825     0.521053  0.046262   \n",
       "\n",
       "       katz      load  is_root  degree_norm  closeness_norm  betweenness_norm  \\\n",
       "0  0.243330  0.415789        1          1.0        0.933542          0.724771   \n",
       "1  0.243500  0.568421        0          1.0        1.000000          0.990826   \n",
       "2  0.218981  0.100000        0          0.5        0.596475          0.174312   \n",
       "3  0.196845  0.000000        0          0.0        0.221956          0.000000   \n",
       "4  0.223220  0.521053        0          0.5        0.836096          0.908257   \n",
       "\n",
       "   pagerank_norm  katz_norm  load_norm    n_norm  \n",
       "0       0.932971   0.996388   0.724771  0.268657  \n",
       "1       0.891309   1.000000   0.990826  0.268657  \n",
       "2       0.518343   0.477072   0.174312  0.268657  \n",
       "3       0.042182   0.004953   0.000000  0.268657  \n",
       "4       0.415764   0.567474   0.908257  0.268657  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/preprocessed/data_normalized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1e64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def kfold_split_by_sentence_language(df, n_splits=5, random_state=42, shuffle=True, output_dir=\"./data/cross_validation\"):\n",
    "    \"\"\"\n",
    "    Performs KFold split ensuring all instances of the same sentence-language pair stay together.\n",
    "    Saves each fold as separate CSV files.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame containing columns 'language' and 'sentence'\n",
    "        n_splits: Number of folds (default: 5)\n",
    "        random_state: Random seed for reproducibility\n",
    "        shuffle: Whether to shuffle data before splitting\n",
    "        output_dir: Directory to save fold CSVs\n",
    "        \n",
    "    Returns:\n",
    "        List of (train_df, test_df) tuples for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Get unique sentence-language pairs\n",
    "    sentence_lang_pairs = df[['language', 'sentence']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Step 2: Setup KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # Step 3: Apply KFold to the pairs\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(sentence_lang_pairs), 1):\n",
    "        train_pairs = sentence_lang_pairs.iloc[train_idx]\n",
    "        test_pairs = sentence_lang_pairs.iloc[test_idx]\n",
    "\n",
    "        # Merge back to get full data for this fold\n",
    "        train_df = pd.merge(df, train_pairs, on=['language', 'sentence'])\n",
    "        test_df = pd.merge(df, test_pairs, on=['language', 'sentence'])\n",
    "\n",
    "        # Save to CSV\n",
    "        train_df.to_csv(f\"{output_dir}/fold_{fold_idx}_train.csv\", index=False)\n",
    "        test_df.to_csv(f\"{output_dir}/fold_{fold_idx}_test.csv\", index=False)\n",
    "        \n",
    "        folds.append((train_df, test_df))\n",
    "\n",
    "    return folds\n",
    "\n",
    "# Usage example:\n",
    "folds = kfold_split_by_sentence_language(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
